{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_CPP_MIN_LOG_LEVEL=3\n"
     ]
    }
   ],
   "source": [
    "%env TF_CPP_MIN_LOG_LEVEL=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод для создания дискриминатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(image_shape):\n",
    "    \n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "    \n",
    "\tin_src_image = Input(shape=image_shape)\n",
    "\tin_target_image = Input(shape=image_shape)\n",
    "    \n",
    "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
    "    \n",
    "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = Activation('sigmoid')(d)\n",
    "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
    "    \n",
    "\topt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "\treturn model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы необходимые для создания генератора на основе модели UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\tg = LeakyReLU(alpha=0.2)(g)\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\tg = BatchNormalization()(g, training=True)\n",
    "\tif dropout:\n",
    "\t\tg = Dropout(0.5)(g, training=True)\n",
    "\tg = Concatenate()([g, skip_in])\n",
    "\tg = Activation('relu')(g)\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(image_shape=(256,256,3)):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tin_image = Input(shape=image_shape)\n",
    "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "\te2 = define_encoder_block(e1, 128)\n",
    "\te3 = define_encoder_block(e2, 256)\n",
    "\te4 = define_encoder_block(e3, 512)\n",
    "\te5 = define_encoder_block(e4, 512)\n",
    "\te6 = define_encoder_block(e5, 512)\n",
    "\te7 = define_encoder_block(e6, 512)\n",
    "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "\tb = Activation('relu')(b)\n",
    "\td1 = decoder_block(b, e7, 512)\n",
    "\td2 = decoder_block(d1, e6, 512)\n",
    "\td3 = decoder_block(d2, e5, 512)\n",
    "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "\tg = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "\tout_image = Activation('tanh')(g)\n",
    "\tmodel = Model(in_image, out_image)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(image_shape=(256,256,3)):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tin_image = Input(shape=image_shape)\n",
    "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "\te2 = define_encoder_block(e1, 128)\n",
    "\te3 = define_encoder_block(e2, 256)\n",
    "\te4 = define_encoder_block(e3, 512)\n",
    "\te5 = define_encoder_block(e4, 512)\n",
    "\te6 = define_encoder_block(e5, 512)\n",
    "\te7 = define_encoder_block(e6, 512)\n",
    "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "\tb = Activation('relu')(b)\n",
    "\td1 = decoder_block(b, e7, 512)\n",
    "\td2 = decoder_block(d1, e6, 512)\n",
    "\td3 = decoder_block(d2, e5, 512)\n",
    "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "\tg = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "\tout_image = Activation('tanh')(g)\n",
    "\tmodel = Model(in_image, out_image)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model, image_shape):\n",
    "\tfor layer in d_model.layers:\n",
    "\t\tif not isinstance(layer, BatchNormalization):\n",
    "\t\t\tlayer.trainable = False \n",
    "            \n",
    "\tin_src = Input(shape=image_shape)\n",
    "\tgen_out = g_model(in_src)\n",
    "\tdis_out = d_model([in_src, gen_out])\n",
    "\tmodel = Model(in_src, [dis_out, gen_out])\n",
    "\topt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    \n",
    "\tmodel.compile(loss=['binary_crossentropy', 'mae'], \n",
    "               optimizer=opt, loss_weights=[1,100])\n",
    "\treturn model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы генерации истиных и ложных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "\ttrainA, trainB = dataset\n",
    "\tix = randint(0, trainA.shape[0], n_samples)\n",
    "\tX1, X2 = trainA[ix], trainB[ix]\n",
    "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "\treturn [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "\tX = g_model.predict(samples)\n",
    "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы для сохренения прогресса обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, dataset, n_samples=3):\n",
    "\t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
    "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "\tX_realA = (X_realA + 1) / 2.0\n",
    "\tX_realB = (X_realB + 1) / 2.0\n",
    "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
    "\n",
    "\tfor i in range(n_samples):\n",
    "\t\tplt.subplot(3, n_samples, 1 + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(X_realA[i])\n",
    "\n",
    "\tfor i in range(n_samples):\n",
    "\t\tplt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(X_fakeB[i])\n",
    "\n",
    "\tfor i in range(n_samples):\n",
    "\t\tplt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(X_realB[i])\n",
    "\n",
    "\tfilename1 = 'plot_%06d.png' % (step+1)\n",
    "\tplt.savefig(os.path.join(r'.\\sample_images', filename1))\n",
    "\tplt.close()\n",
    "\n",
    "\tfilename2 = 'model_%06d.h5' % (step+1)\n",
    "\tg_model.save(os.path.join(r'.\\models\\gan', filename2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model, save_model\n",
    "\n",
    "def save(gan, generator, discriminator):\n",
    "    root_path = r'.\\models\\training'\n",
    "    discriminator.trainable = False\n",
    "    save_model(gan, os.path.join(root_path, 'gan'))\n",
    "    discriminator.trainable = True\n",
    "    save_model(generator, os.path.join(root_path, 'generator'))\n",
    "    save_model(discriminator, os.path.join(root_path, 'discriminator'))\n",
    "\n",
    "def load():\n",
    "    root_path = ''\n",
    "    discriminator = load_model(os.path.join(root_path, 'discriminator'))\n",
    "    generator = load_model(os.path.join(root_path, 'generator'))\n",
    "    gan = load_model(os.path.join(root_path, 'gan'))\n",
    "    gan.summary()\n",
    "    discriminator.summary()\n",
    "    generator.summary()\n",
    "\n",
    "    return gan, generator, discriminator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n",
    "\tn_patch = d_model.output_shape[1]\n",
    "\ttrainA, trainB = dataset\n",
    "\tbat_per_epo = int(len(trainA) / n_batch)\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "\t\tprint(f'Эпоха: {((i+1) // bat_per_epo) + 1}')\n",
    "\t\tprint('Итерация: %d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "\t\tif (i+1) % (bat_per_epo * 1) == 0: # Сохраняем модель генератора и набор изображений каждую (1) эпоху. \n",
    "\t\t\tsummarize_performance(i, g_model, dataset)\n",
    "\t\t\tsave(gan_model, g_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from numpy import asarray, load\n",
    "from numpy import vstack\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.utils import load_img\n",
    "from numpy import savez_compressed\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и предобработка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(images_path,  mask_path, size=(256,256)):\n",
    "\tsrc_list, tar_list = list(), list()\n",
    "\timages = sorted(os.listdir(images_path))\n",
    "\tmasks = sorted(os.listdir(mask_path))\n",
    "\tfor i in range(len(images)):      \n",
    "\t\timg_pixels = load_img(os.path.join(images_path, images[i]), target_size=size)\n",
    "\t\timg = img_to_array(img_pixels)\n",
    "\n",
    "\t\tmask_pixels = load_img(os.path.join(mask_path, masks[i]), target_size=size)\n",
    "\t\tmask = img_to_array(mask_pixels)\n",
    "\t\n",
    "\t\tsrc_list.append(img)\n",
    "\t\ttar_list.append(mask)\n",
    "\n",
    "\treturn [asarray(src_list), asarray(tar_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено:  (3831, 256, 256, 3) (3831, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "img_path = r'.\\dataset\\Forest Segmented\\train_data\\train_image\\train'\n",
    "mask_path = r'.\\dataset\\Forest Segmented\\train_data\\train_mask\\train'\n",
    "[src_images, tar_images] = load_images(img_path, mask_path)\n",
    "print('Загружено: ', src_images.shape, tar_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [src_images, tar_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = src_images.shape[1:]\n",
    "\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "gan_model = define_gan(g_model, d_model, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data): \n",
    "\timg, mask = data[0], data[1]\n",
    "\t\n",
    "\timg = img  / 256.0\n",
    "\t\n",
    "\treturn [img, mask]\n",
    "\n",
    "dataset = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели (так как собираемые метрки смысловой нагрузки не несут, а занимали очень много места они были удалены)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели:  13:39:02.663692 (Одна эпоха: 3.1952219666666664 минут)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "start1 = datetime.now() \n",
    "\n",
    "train(d_model, g_model, gan_model, dataset, n_epochs=n_epochs, n_batch=32) \n",
    "\n",
    "stop1 = datetime.now()\n",
    "\n",
    "execution_time = stop1-start1\n",
    "print(\"Время обучения модели: \", execution_time, f\"(\\nОдна эпоха: {(execution_time/n_epochs).total_seconds()/60} минут)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.save(r'./models/Method2_Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
